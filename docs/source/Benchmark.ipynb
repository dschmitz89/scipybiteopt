{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark against scipy\n",
    "\n",
    "As biteopt is implemented in C++ its inner loops can be expected to run a lot faster than scipy's solvers which are coded in Python. However, this only matters for inexpensive objective functions which are very fast to evaluate. For expensive objective functions, a low number of function evaluations is crucial for a fast optimization process. In that scenario biteopt has the disadvantage that it does not perform any convergence checks and always runs for the maximum number of function evaluations. \n",
    "\n",
    "Here we will benchmark biteopt against scipy's most powerful stochastic optimizers on a famous test function for optimization which can be computed very quickly: the Rastrigin function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipybiteopt import biteopt\n",
    "from scipy.optimize import dual_annealing, differential_evolution\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules are: No local optimizations allowed (therefore `no_local_search=True` for `dual_annealing` and `polish = False` for `differential_evolution`) as we want to compare the performance of the stochastic optimizers. We keep the default number of function evaluations ad termination criteria. We use a moderately large number of dimensions: `d = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy Dual Annealing: minimal value=7.229606865166716e-06, number of function evaluations=20001\n",
      "902 ms ± 15.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Scipy Differential Evolution: minimal value=0.9970061264923658, number of function evaluations=105750\n",
      "4.61 s ± 1.1 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Biteopt: minimal value=4.5713477447861806e-10, number of function evaluations=10000\n",
      "82.3 ms ± 2.18 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def rastrigin(x):\n",
    "    return np.sum(x*x - 10*np.cos(2*np.pi*x)) + 10*x.shape[0]\n",
    "\n",
    "lower_bounds = [-8.12] * 10\n",
    "upper_bounds = [5.12] * 10\n",
    "bounds=list(zip(lower_bounds, upper_bounds))\n",
    "\n",
    "res_da = dual_annealing(rastrigin, bounds, no_local_search=True)\n",
    "print(\"Scipy Dual Annealing: minimal value={}, number of function evaluations={}\".format(res_da.fun, res_da.nfev))\n",
    "%timeit -n 1 res_da = dual_annealing(rastrigin, bounds, no_local_search=True)\n",
    "\n",
    "\n",
    "print()\n",
    "res_de = differential_evolution(rastrigin, bounds, polish = False)\n",
    "print(\"Scipy Differential Evolution: minimal value={}, number of function evaluations={}\".format(res_de.fun, res_bo.nfev))\n",
    "%timeit -n 1 res_de = differential_evolution(rastrigin, bounds, polish = False)\n",
    "\n",
    "print()\n",
    "res_bo = biteopt(rastrigin, bounds)\n",
    "print(\"Biteopt: minimal value={}, number of function evaluations={}\".format(res_bo.fun, res_bo.nfev))\n",
    "%timeit -n 1 res_bo = biteopt(rastrigin, bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `biteopt` is app. 10 times faster than `dual_annealing` and 50 times faster than `differential-evolution`.\n",
    "\n",
    "Let's see how this changes when  the objective function is also compiled and no longer uses the Python interpreter. For that we will use numba's convenient just in time compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy Dual Annealing: minimal value=5.246936069625008e-06, number of function evaluations=20001\n",
      "706 ms ± 15.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Scipy Differential Evolution: minimal value=0.0, number of function evaluations=109200\n",
      "4.41 s ± 668 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Biteopt: minimal value=0.0, number of function evaluations=10000\n",
      "10.7 ms ± 264 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from numba import njit\n",
    "\n",
    "#let numba JIT compile\n",
    "rastrigin_compiled = njit(rastrigin)\n",
    "out = rastrigin_compiled(np.zeros((dimension, )))\n",
    "\n",
    "res_da = dual_annealing(rastrigin_compiled, bounds, no_local_search=True)\n",
    "print(\"Scipy Dual Annealing: minimal value={}, number of function evaluations={}\".format(res_da.fun, res_da.nfev))\n",
    "%timeit -n 1 res_da = dual_annealing(rastrigin_compiled, bounds, no_local_search=True)\n",
    "\n",
    "print()\n",
    "res_de = differential_evolution(rastrigin_compiled, bounds, polish = False)\n",
    "print(\"Scipy Differential Evolution: minimal value={}, number of function evaluations={}\".format(res_de.fun, res_de.nfev))\n",
    "%timeit -n 1 res_de = differential_evolution(rastrigin_compiled, bounds, polish = False)\n",
    "\n",
    "print()\n",
    "res_bo = biteopt(rastrigin_compiled, bounds)\n",
    "print(\"Biteopt: minimal value={}, number of function evaluations={}\".format(res_bo.fun, res_bo.nfev))\n",
    "%timeit -n 1 res_bo = biteopt(rastrigin_compiled, bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `biteopt` is app. 70 times faster than `dual_annealing` and 400 times faster than `differential-evolution`!\n",
    "\n",
    "Note that this comes with a tradeoff though: biteopt does not perform any sanity checks. Using scipybiteopt can be like using raw C/C++: Errors or exceptions occuring during evaluation of the objective are not caught and might crash the Python interpreter. Help is always welcome to make this wrapper more robust."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
